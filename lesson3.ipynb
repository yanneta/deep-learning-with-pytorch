{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for this notebook comes from this kaggle [competition](https://www.kaggle.com/c/wids2018datathon/). You are given a dataset of survey questions and results from a developing country. Your goal is to predict the gender of the respondent based on the other answers he/she provided. You Kaggle api to get the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install kaggle` <br/>\n",
    "\n",
    "`kaggle competitions download -c wids2018datathon -p /data/yinterian/WiDS18`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH = Path(\"/data/yinterian/WiDS18/\")\n",
    "PATH = Path(\"/Users/yinterian/teaching/deeplearning/data/WiDS18/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id  AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  is_female  \\\n",
       "0         0    3   32  3.0  NaN  323011  3854   481  1975          1   \n",
       "1         1    2   26  NaN  8.0  268131  2441   344  1981          1   \n",
       "2         2    1   16  NaN  7.0  167581   754   143  1995          1   \n",
       "3         3    4   44  5.0  NaN  445071  5705   604  1980          1   \n",
       "4         4    4   43  NaN  6.0  436161  5645   592  1958          1   \n",
       "\n",
       "      ...       GN1  GN1_OTHERS GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  \\\n",
       "0     ...      99.0         NaN  99         NaN   99         NaN   99   \n",
       "1     ...       NaN         NaN   1         NaN    2         NaN    2   \n",
       "2     ...       1.0         NaN   2         NaN    2         NaN    2   \n",
       "3     ...       NaN         NaN   2         NaN    2         NaN   99   \n",
       "4     ...       NaN         NaN   1         NaN    1         NaN    1   \n",
       "\n",
       "   GN4_OTHERS  GN5  GN5_OTHERS  \n",
       "0         NaN   99         NaN  \n",
       "1         NaN    2         NaN  \n",
       "2         NaN    2         NaN  \n",
       "3         NaN   99         NaN  \n",
       "4         NaN    1         NaN  \n",
       "\n",
       "[5 rows x 1235 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(PATH/\"train.csv\", low_memory=False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18255, 1235)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA5</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>DG3</th>\n",
       "      <th>...</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN1_OTHERS</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN2_OTHERS</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN3_OTHERS</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN4_OTHERS</th>\n",
       "      <th>GN5</th>\n",
       "      <th>GN5_OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA5  AA6     AA7  AA14  AA15   DG1  is_female  DG3     ...      \\\n",
       "0    3   32  3.0  NaN  323011  3854   481  1975          1    3     ...       \n",
       "1    2   26  NaN  8.0  268131  2441   344  1981          1    8     ...       \n",
       "2    1   16  NaN  7.0  167581   754   143  1995          1    3     ...       \n",
       "3    4   44  5.0  NaN  445071  5705   604  1980          1    3     ...       \n",
       "4    4   43  NaN  6.0  436161  5645   592  1958          1    3     ...       \n",
       "\n",
       "    GN1 GN1_OTHERS  GN2  GN2_OTHERS  GN3  GN3_OTHERS  GN4  GN4_OTHERS  GN5  \\\n",
       "0  99.0        NaN   99         NaN   99         NaN   99         NaN   99   \n",
       "1   NaN        NaN    1         NaN    2         NaN    2         NaN    2   \n",
       "2   1.0        NaN    2         NaN    2         NaN    2         NaN    2   \n",
       "3   NaN        NaN    2         NaN    2         NaN   99         NaN   99   \n",
       "4   NaN        NaN    1         NaN    1         NaN    1         NaN    1   \n",
       "\n",
       "   GN5_OTHERS  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  \n",
       "\n",
       "[5 rows x 1234 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(columns=[\"train_id\"])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning columns with too many NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12602"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"AA5\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AA3                     0\n",
       "AA4                     0\n",
       "AA6                  5653\n",
       "AA7                     0\n",
       "AA14                    0\n",
       "AA15                    0\n",
       "DG1                     0\n",
       "is_female               0\n",
       "DG3                     0\n",
       "DG3A                    0\n",
       "DG4                     0\n",
       "DG5_1                   0\n",
       "DG5_2                   0\n",
       "DG5_3                   0\n",
       "DG5_4                   0\n",
       "DG5_5                   0\n",
       "DG5_6                   0\n",
       "DG5_7                   0\n",
       "DG5_8                   0\n",
       "DG5_9                   0\n",
       "DG5_10                  0\n",
       "DG5_11                  0\n",
       "DG5_96                  0\n",
       "DG6                     0\n",
       "DG8a                    0\n",
       "DG8b                    0\n",
       "DG8c                    0\n",
       "DG9a                  232\n",
       "DG9b                10018\n",
       "DG9c                11451\n",
       "                    ...  \n",
       "FB27_1                  0\n",
       "FB27_2                  0\n",
       "FB27_3                  0\n",
       "FB27_4                  0\n",
       "FB27_5                  0\n",
       "FB27_6                  0\n",
       "FB27_7                  0\n",
       "FB27_8                  0\n",
       "FB27_9                  0\n",
       "FB27_96                 0\n",
       "FB29_1                  0\n",
       "FB29_2                  0\n",
       "FB29_3                  0\n",
       "FB29_4                  0\n",
       "FB29_5                  0\n",
       "FB29_6                  0\n",
       "FB29_96                 0\n",
       "LN1A                    0\n",
       "LN1B                    0\n",
       "LN2_1                   0\n",
       "LN2_2                   0\n",
       "LN2_3                   0\n",
       "LN2_4                   0\n",
       "LN2_RIndLngBEOth     6914\n",
       "LN2_WIndLngBEOth     6911\n",
       "GN1                  4025\n",
       "GN2                     0\n",
       "GN3                     0\n",
       "GN4                     0\n",
       "GN5                     0\n",
       "Length: 421, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dropping columns with too many nulls\n",
    "for col in train.columns:\n",
    "    if train[col].isnull().sum() > 12000:\n",
    "        #print(col, train[col].isnull().sum())\n",
    "        train.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>is_female</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>LN2_RIndLngBEOth</th>\n",
       "      <th>LN2_WIndLngBEOth</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>323011</td>\n",
       "      <td>3854</td>\n",
       "      <td>481</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99.0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>8.0</td>\n",
       "      <td>268131</td>\n",
       "      <td>2441</td>\n",
       "      <td>344</td>\n",
       "      <td>1981</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>167581</td>\n",
       "      <td>754</td>\n",
       "      <td>143</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>445071</td>\n",
       "      <td>5705</td>\n",
       "      <td>604</td>\n",
       "      <td>1980</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>Tamil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>6.0</td>\n",
       "      <td>436161</td>\n",
       "      <td>5645</td>\n",
       "      <td>592</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>Malayalam</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AA3  AA4  AA6     AA7  AA14  AA15   DG1  is_female  DG3  DG3A ...   LN2_2  \\\n",
       "0    3   32  NaN  323011  3854   481  1975          1    3     4 ...       1   \n",
       "1    2   26  8.0  268131  2441   344  1981          1    8     4 ...       1   \n",
       "2    1   16  7.0  167581   754   143  1995          1    3     2 ...       1   \n",
       "3    4   44  NaN  445071  5705   604  1980          1    3     4 ...       1   \n",
       "4    4   43  6.0  436161  5645   592  1958          1    3     4 ...       4   \n",
       "\n",
       "   LN2_3  LN2_4  LN2_RIndLngBEOth  LN2_WIndLngBEOth   GN1  GN2  GN3  GN4  GN5  \n",
       "0      1      1               NaN               NaN  99.0   99   99   99   99  \n",
       "1      3      4           Bengali           Bengali   NaN    1    2    2    2  \n",
       "2      2      2             Hindi             Hindi   1.0    2    2    2    2  \n",
       "3      4      5             Tamil             Tamil   NaN    2    2   99   99  \n",
       "4      4      4         Malayalam         Malayalam   NaN    1    1    1    1  \n",
       "\n",
       "[5 rows x 421 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just kept 421 columns\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18255, 421)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(PATH/\"train_421_cols.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking columns for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(PATH/\"train_421_cols.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train[\"is_female\"].values.astype(np.float32)\n",
    "X = train.drop(columns=[\"is_female\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "for col in X.columns:\n",
    "    if X.dtypes[col] == \"object\":\n",
    "        X[col] = X[col].fillna(\"NA\")\n",
    "    else:\n",
    "        X[col] = X[col].fillna(0)\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X.columns:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AA3</th>\n",
       "      <th>AA4</th>\n",
       "      <th>AA6</th>\n",
       "      <th>AA7</th>\n",
       "      <th>AA14</th>\n",
       "      <th>AA15</th>\n",
       "      <th>DG1</th>\n",
       "      <th>DG3</th>\n",
       "      <th>DG3A</th>\n",
       "      <th>DG4</th>\n",
       "      <th>...</th>\n",
       "      <th>LN2_2</th>\n",
       "      <th>LN2_3</th>\n",
       "      <th>LN2_4</th>\n",
       "      <th>LN2_RIndLngBEOth</th>\n",
       "      <th>LN2_WIndLngBEOth</th>\n",
       "      <th>GN1</th>\n",
       "      <th>GN2</th>\n",
       "      <th>GN3</th>\n",
       "      <th>GN4</th>\n",
       "      <th>GN5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11369</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>424</td>\n",
       "      <td>482</td>\n",
       "      <td>252</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>831</td>\n",
       "      <td>831</td>\n",
       "      <td>410</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>301</td>\n",
       "      <td>310</td>\n",
       "      <td>166</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13476</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>664</td>\n",
       "      <td>564</td>\n",
       "      <td>300</td>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13406</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>587</td>\n",
       "      <td>111</td>\n",
       "      <td>76</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 420 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AA3 AA4 AA6  AA7 AA14 AA15 DG1 DG3 DG3A DG4 ... LN2_2 LN2_3 LN2_4  \\\n",
       "11369   1  10   2  424  482  252  62   2    3   4 ...     0     0     0   \n",
       "1250    2  17   1  831  831  410  63   2    3   5 ...     0     3     3   \n",
       "7527    1   8   0  301  310  166  53   2    3   0 ...     0     0     0   \n",
       "13476   2  14   2  664  564  300  69   2    3   4 ...     2     2     2   \n",
       "13406   0  12   3  587  111   76  58   2    3   2 ...     1     3     3   \n",
       "\n",
       "      LN2_RIndLngBEOth LN2_WIndLngBEOth GN1 GN2 GN3 GN4 GN5  \n",
       "11369               38               38   0   1   1   1   1  \n",
       "1250                33               32   1   2   2   0   0  \n",
       "7527                38               38   2   1   1   1   1  \n",
       "13476               14               14   3   2   2   2   2  \n",
       "13406               14               14   1   0   2   2   2  \n",
       "\n",
       "[5 rows x 420 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.20, random_state=3)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AA3': 4,\n",
       " 'AA4': 22,\n",
       " 'AA6': 4,\n",
       " 'AA7': 1050,\n",
       " 'AA14': 907,\n",
       " 'AA15': 450,\n",
       " 'DG1': 79,\n",
       " 'DG3': 9,\n",
       " 'DG3A': 8,\n",
       " 'DG4': 12,\n",
       " 'DG6': 9,\n",
       " 'DG8a': 13,\n",
       " 'DG8b': 13,\n",
       " 'DG8c': 13,\n",
       " 'DG9a': 12,\n",
       " 'DG9b': 11,\n",
       " 'DG9c': 8,\n",
       " 'DG10b': 9,\n",
       " 'DG10c': 8,\n",
       " 'DG11b': 9,\n",
       " 'DL1': 12,\n",
       " 'DL2': 33,\n",
       " 'DL3': 3,\n",
       " 'DL5': 25,\n",
       " 'DL7': 3,\n",
       " 'DL8': 342,\n",
       " 'DL11': 15,\n",
       " 'DL14': 24,\n",
       " 'DL15': 4,\n",
       " 'DL24': 7,\n",
       " 'MT1': 13,\n",
       " 'MT1A': 8,\n",
       " 'MT3_1': 5,\n",
       " 'MT3_2': 6,\n",
       " 'MT3_3': 6,\n",
       " 'MT4_1': 3,\n",
       " 'MT4_2': 3,\n",
       " 'MT4_3': 3,\n",
       " 'MT4_4': 3,\n",
       " 'MT4_5': 3,\n",
       " 'MT4_6': 3,\n",
       " 'MT5': 8,\n",
       " 'MT6': 10,\n",
       " 'MT6A': 7,\n",
       " 'MT6B': 9,\n",
       " 'MT6C': 28,\n",
       " 'MT7': 3,\n",
       " 'MT11': 83,\n",
       " 'MT12_1': 5,\n",
       " 'MT12_2': 7,\n",
       " 'MT12_3': 6,\n",
       " 'MT12_4': 3,\n",
       " 'MT12_5': 3,\n",
       " 'MT12_7': 5,\n",
       " 'MT12_9': 3,\n",
       " 'MT12_11': 5,\n",
       " 'MT12_12': 3,\n",
       " 'MT12_13': 3,\n",
       " 'MT12_14': 3,\n",
       " 'MT14C_1': 5,\n",
       " 'MT14C_2': 5,\n",
       " 'MT14C_3': 5,\n",
       " 'MT14C_4': 5,\n",
       " 'MT15': 3,\n",
       " 'MT17_1': 7,\n",
       " 'MT17_2': 7,\n",
       " 'MT17_3': 7,\n",
       " 'MT17_4': 7,\n",
       " 'MT17_5': 7,\n",
       " 'MT17_6': 7,\n",
       " 'MT17_7': 7,\n",
       " 'MT17_8': 7,\n",
       " 'MT17_9': 7,\n",
       " 'MT17_10': 7,\n",
       " 'MT17_11': 7,\n",
       " 'MT17_12': 7,\n",
       " 'MT17_13': 7,\n",
       " 'MT18_1': 3,\n",
       " 'MT18_2': 3,\n",
       " 'MT18_3': 3,\n",
       " 'MT18_4': 3,\n",
       " 'MT18_5': 3,\n",
       " 'MT18_6': 3,\n",
       " 'MT18_96': 3,\n",
       " 'MT18_8': 3,\n",
       " 'FF2': 4,\n",
       " 'FF2A': 18,\n",
       " 'FF3': 27,\n",
       " 'FF4': 3,\n",
       " 'FF5': 4,\n",
       " 'FF6_1': 4,\n",
       " 'FF6_2': 4,\n",
       " 'FF6_3': 4,\n",
       " 'FF6_4': 4,\n",
       " 'FF6_5': 4,\n",
       " 'FF6_6': 4,\n",
       " 'FF6_7': 4,\n",
       " 'FF6_8': 4,\n",
       " 'FF6_9': 4,\n",
       " 'FF6_10': 4,\n",
       " 'FF7_1': 4,\n",
       " 'FF7_2': 4,\n",
       " 'FF7_4': 5,\n",
       " 'FF7_5': 4,\n",
       " 'FF7_6': 3,\n",
       " 'FF9': 7,\n",
       " 'FF10_1': 3,\n",
       " 'FF10_2': 3,\n",
       " 'FF10_3': 3,\n",
       " 'FF10_4': 3,\n",
       " 'FF10_5': 3,\n",
       " 'FF10_6': 3,\n",
       " 'FF10_96': 3,\n",
       " 'FF13': 8,\n",
       " 'FF14_1': 3,\n",
       " 'FF14_2': 3,\n",
       " 'FF14_3': 3,\n",
       " 'FF14_4': 3,\n",
       " 'FF14_5': 3,\n",
       " 'FF14_6': 3,\n",
       " 'FF14_7': 3,\n",
       " 'FF14_8': 3,\n",
       " 'FF14_9': 3,\n",
       " 'FF14_10': 3,\n",
       " 'FF14_11': 3,\n",
       " 'FF14_12': 3,\n",
       " 'FF14_13': 3,\n",
       " 'FF14_14': 3,\n",
       " 'FF14_15': 3,\n",
       " 'FF14_16': 3,\n",
       " 'FF14_17': 3,\n",
       " 'FF14_18': 3,\n",
       " 'FF14_19': 3,\n",
       " 'FF14_20': 3,\n",
       " 'FF14_21': 3,\n",
       " 'FF14_22': 3,\n",
       " 'FF14_23': 3,\n",
       " 'FF14_96': 3,\n",
       " 'FF16_1': 6,\n",
       " 'FF16_2': 6,\n",
       " 'FF19_1': 3,\n",
       " 'FF19_2': 3,\n",
       " 'FF19_3': 3,\n",
       " 'FF19_4': 3,\n",
       " 'FF19_5': 3,\n",
       " 'FF19_6': 3,\n",
       " 'FF19_7': 3,\n",
       " 'FF19_8': 3,\n",
       " 'MM3_1': 3,\n",
       " 'MM3_2': 3,\n",
       " 'MM3_3': 3,\n",
       " 'MM3_4': 3,\n",
       " 'MM3_5': 3,\n",
       " 'MM3_6': 3,\n",
       " 'MM3_7': 3,\n",
       " 'MM3_8': 3,\n",
       " 'MM3_9': 3,\n",
       " 'MM3_10': 3,\n",
       " 'MM3_11': 3,\n",
       " 'MM3_12': 3,\n",
       " 'MM3_13': 3,\n",
       " 'MM3_14': 3,\n",
       " 'IFI14_1': 7,\n",
       " 'IFI14_2': 7,\n",
       " 'IFI14_3': 7,\n",
       " 'IFI14_4': 7,\n",
       " 'IFI14_5': 7,\n",
       " 'IFI14_6': 7,\n",
       " 'IFI14_7': 7,\n",
       " 'IFI15_1': 7,\n",
       " 'IFI15_2': 7,\n",
       " 'IFI15_3': 7,\n",
       " 'IFI15_4': 7,\n",
       " 'IFI15_5': 7,\n",
       " 'IFI15_6': 7,\n",
       " 'IFI15_7': 7,\n",
       " 'IFI16_1': 11,\n",
       " 'IFI16_2': 11,\n",
       " 'IFI17_1': 7,\n",
       " 'IFI17_2': 7,\n",
       " 'IFI18': 9,\n",
       " 'IFI24': 12,\n",
       " 'FL1': 4,\n",
       " 'FL2': 5,\n",
       " 'FL3': 10,\n",
       " 'FL4': 19,\n",
       " 'FL7_1': 3,\n",
       " 'FL7_2': 3,\n",
       " 'FL7_3': 3,\n",
       " 'FL7_4': 3,\n",
       " 'FL7_5': 3,\n",
       " 'FL7_6': 3,\n",
       " 'FL8_1': 5,\n",
       " 'FL8_2': 5,\n",
       " 'FL8_3': 5,\n",
       " 'FL8_4': 5,\n",
       " 'FL8_5': 5,\n",
       " 'FL8_6': 5,\n",
       " 'FL8_7': 5,\n",
       " 'FL9A': 12,\n",
       " 'FL9B': 13,\n",
       " 'FL9C': 13,\n",
       " 'FL10': 13,\n",
       " 'FL11': 5,\n",
       " 'FL12': 3,\n",
       " 'FL14': 3,\n",
       " 'FL15': 4,\n",
       " 'FL16': 3,\n",
       " 'FL17': 3,\n",
       " 'FL18': 3,\n",
       " 'FB2': 3,\n",
       " 'FB13': 25,\n",
       " 'FB18': 5,\n",
       " 'FB19': 11,\n",
       " 'FB19B_1': 4,\n",
       " 'FB19B_2': 4,\n",
       " 'FB19B_3': 4,\n",
       " 'FB19B_4': 4,\n",
       " 'FB19B_5': 4,\n",
       " 'FB19B_96': 4,\n",
       " 'FB20': 16,\n",
       " 'FB24': 17,\n",
       " 'FB26_1': 3,\n",
       " 'FB26_2': 3,\n",
       " 'FB26_3': 3,\n",
       " 'FB26_4': 3,\n",
       " 'FB26_5': 3,\n",
       " 'FB26_6': 3,\n",
       " 'FB26_7': 3,\n",
       " 'FB26_8': 3,\n",
       " 'FB26_9': 3,\n",
       " 'FB26_10': 3,\n",
       " 'FB26_11': 3,\n",
       " 'FB26_96': 3,\n",
       " 'FB26_99': 3,\n",
       " 'LN1A': 4,\n",
       " 'LN1B': 4,\n",
       " 'LN2_1': 5,\n",
       " 'LN2_2': 5,\n",
       " 'LN2_3': 5,\n",
       " 'LN2_4': 5,\n",
       " 'LN2_RIndLngBEOth': 58,\n",
       " 'LN2_WIndLngBEOth': 59,\n",
       " 'GN1': 7,\n",
       " 'GN2': 6,\n",
       " 'GN3': 6,\n",
       " 'GN4': 6,\n",
       " 'GN5': 6}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of categories for categories with more than 2 categories\n",
    "emb_c = {n: len(col.cat.categories) for n,col in X.items() if len(col.cat.categories) > 2}\n",
    "emb_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 2),\n",
       " (22, 11),\n",
       " (4, 2),\n",
       " (1050, 50),\n",
       " (907, 50),\n",
       " (450, 50),\n",
       " (79, 40),\n",
       " (9, 5),\n",
       " (8, 4),\n",
       " (12, 6),\n",
       " (9, 5),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (12, 6),\n",
       " (11, 6),\n",
       " (8, 4),\n",
       " (9, 5),\n",
       " (8, 4),\n",
       " (9, 5),\n",
       " (12, 6),\n",
       " (33, 17),\n",
       " (3, 2),\n",
       " (25, 13),\n",
       " (3, 2),\n",
       " (342, 50),\n",
       " (15, 8),\n",
       " (24, 12),\n",
       " (4, 2),\n",
       " (7, 4),\n",
       " (13, 7),\n",
       " (8, 4),\n",
       " (5, 3),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (8, 4),\n",
       " (10, 5),\n",
       " (7, 4),\n",
       " (9, 5),\n",
       " (28, 14),\n",
       " (3, 2),\n",
       " (83, 42),\n",
       " (5, 3),\n",
       " (7, 4),\n",
       " (6, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (18, 9),\n",
       " (27, 14),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (5, 3),\n",
       " (4, 2),\n",
       " (3, 2),\n",
       " (7, 4),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (8, 4),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (11, 6),\n",
       " (11, 6),\n",
       " (7, 4),\n",
       " (7, 4),\n",
       " (9, 5),\n",
       " (12, 6),\n",
       " (4, 2),\n",
       " (5, 3),\n",
       " (10, 5),\n",
       " (19, 10),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (12, 6),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (13, 7),\n",
       " (5, 3),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (25, 13),\n",
       " (5, 3),\n",
       " (11, 6),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (16, 8),\n",
       " (17, 9),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (4, 2),\n",
       " (4, 2),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (5, 3),\n",
       " (58, 29),\n",
       " (59, 30),\n",
       " (7, 4),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (6, 3),\n",
       " (6, 3)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the category, size of the embedding\n",
    "# 30 and (c+1)//2) are arbitrary (we should play with these numbers)\n",
    "emb_szs = [(c, min(50, (c+1)//2)) for _,c in emb_c.items()]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AA3', 'AA4', 'AA6', 'AA7', 'AA14', 'AA15', 'DG1', 'DG3', 'DG3A', 'DG4', 'DG6', 'DG8a', 'DG8b', 'DG8c', 'DG9a', 'DG9b', 'DG9c', 'DG10b', 'DG10c', 'DG11b', 'DL1', 'DL2', 'DL3', 'DL5', 'DL7', 'DL8', 'DL11', 'DL14', 'DL15', 'DL24', 'MT1', 'MT1A', 'MT3_1', 'MT3_2', 'MT3_3', 'MT4_1', 'MT4_2', 'MT4_3', 'MT4_4', 'MT4_5', 'MT4_6', 'MT5', 'MT6', 'MT6A', 'MT6B', 'MT6C', 'MT7', 'MT11', 'MT12_1', 'MT12_2', 'MT12_3', 'MT12_4', 'MT12_5', 'MT12_7', 'MT12_9', 'MT12_11', 'MT12_12', 'MT12_13', 'MT12_14', 'MT14C_1', 'MT14C_2', 'MT14C_3', 'MT14C_4', 'MT15', 'MT17_1', 'MT17_2', 'MT17_3', 'MT17_4', 'MT17_5', 'MT17_6', 'MT17_7', 'MT17_8', 'MT17_9', 'MT17_10', 'MT17_11', 'MT17_12', 'MT17_13', 'MT18_1', 'MT18_2', 'MT18_3', 'MT18_4', 'MT18_5', 'MT18_6', 'MT18_96', 'MT18_8', 'FF2', 'FF2A', 'FF3', 'FF4', 'FF5', 'FF6_1', 'FF6_2', 'FF6_3', 'FF6_4', 'FF6_5', 'FF6_6', 'FF6_7', 'FF6_8', 'FF6_9', 'FF6_10', 'FF7_1', 'FF7_2', 'FF7_4', 'FF7_5', 'FF7_6', 'FF9', 'FF10_1', 'FF10_2', 'FF10_3', 'FF10_4', 'FF10_5', 'FF10_6', 'FF10_96', 'FF13', 'FF14_1', 'FF14_2', 'FF14_3', 'FF14_4', 'FF14_5', 'FF14_6', 'FF14_7', 'FF14_8', 'FF14_9', 'FF14_10', 'FF14_11', 'FF14_12', 'FF14_13', 'FF14_14', 'FF14_15', 'FF14_16', 'FF14_17', 'FF14_18', 'FF14_19', 'FF14_20', 'FF14_21', 'FF14_22', 'FF14_23', 'FF14_96', 'FF16_1', 'FF16_2', 'FF19_1', 'FF19_2', 'FF19_3', 'FF19_4', 'FF19_5', 'FF19_6', 'FF19_7', 'FF19_8', 'MM3_1', 'MM3_2', 'MM3_3', 'MM3_4', 'MM3_5', 'MM3_6', 'MM3_7', 'MM3_8', 'MM3_9', 'MM3_10', 'MM3_11', 'MM3_12', 'MM3_13', 'MM3_14', 'IFI14_1', 'IFI14_2', 'IFI14_3', 'IFI14_4', 'IFI14_5', 'IFI14_6', 'IFI14_7', 'IFI15_1', 'IFI15_2', 'IFI15_3', 'IFI15_4', 'IFI15_5', 'IFI15_6', 'IFI15_7', 'IFI16_1', 'IFI16_2', 'IFI17_1', 'IFI17_2', 'IFI18', 'IFI24', 'FL1', 'FL2', 'FL3', 'FL4', 'FL7_1', 'FL7_2', 'FL7_3', 'FL7_4', 'FL7_5', 'FL7_6', 'FL8_1', 'FL8_2', 'FL8_3', 'FL8_4', 'FL8_5', 'FL8_6', 'FL8_7', 'FL9A', 'FL9B', 'FL9C', 'FL10', 'FL11', 'FL12', 'FL14', 'FL15', 'FL16', 'FL17', 'FL18', 'FB2', 'FB13', 'FB18', 'FB19', 'FB19B_1', 'FB19B_2', 'FB19B_3', 'FB19B_4', 'FB19B_5', 'FB19B_96', 'FB20', 'FB24', 'FB26_1', 'FB26_2', 'FB26_3', 'FB26_4', 'FB26_5', 'FB26_6', 'FB26_7', 'FB26_8', 'FB26_9', 'FB26_10', 'FB26_11', 'FB26_96', 'FB26_99', 'LN1A', 'LN1B', 'LN2_1', 'LN2_2', 'LN2_3', 'LN2_4', 'LN2_RIndLngBEOth', 'LN2_WIndLngBEOth', 'GN1', 'GN2', 'GN3', 'GN4', 'GN5'])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_cols = emb_c.keys()\n",
    "emb_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Dataset is a custom class to conveniently interact with a set observations. Designing this Dataset class is up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all variables are categorical, but some of them has just two values \n",
    "# emb_c are the variables we plan to embed\n",
    "class WiDSDataset(Dataset):\n",
    "    def __init__(self, X, Y, emb_cols):\n",
    "        X = X.copy()\n",
    "        # splitting categorical columns and numerical columns\n",
    "        self.X1 = X.loc[:,emb_cols].copy().values.astype(np.int64)\n",
    "        self.X2 = X.drop(columns=emb_cols).copy().values.astype(np.float32)\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X1[idx], self.X2[idx], self.y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = WiDSDataset(X_train, y_train, emb_cols)\n",
    "valid_ds = WiDSDataset(X_val, y_val, emb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0,   4,   3, 200, 229, 129,  72,   0,   3,   5,   2,   5,   3,\n",
       "          1,   3,   0,   0,   3,   0,   3,   5,   0,   0,   0,   1, 136,\n",
       "          0,   8,   3,   0,   1,   7,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   1,   2,   0,   0,   1,   3,\n",
       "          1,   3,   2,   1,   2,   3,   2,   2,   2,   0,   0,   1,   0,\n",
       "          0,   4,   1,   2,   2,   2,   2,   2,   2,   1,   1,   1,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   4,   4,   2,   2,   2,\n",
       "          2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
       "          2,   2,   2,   2,   0,   2,   2,   6,   6,   6,   6,   6,   6,\n",
       "          1,   6,   6,   6,   6,   6,   6,   6,   0,   1,   0,   8,   0,\n",
       "          3,   0,   0,   7,   1,   1,   1,   1,   1,   1,   1,   3,   2,\n",
       "          1,   1,   3,   2,  10,   0,   0,   0,   1,   0,   0,   0,   1,\n",
       "          0,   0,   1,  24,   4,   9,   3,   2,   2,   2,   2,   2,  15,\n",
       "          0,   2,   2,   2,   2,   1,   1,   1,   1,   2,   2,   1,   2,\n",
       "          2,   1,   1,   0,   0,   3,   3,  14,  14,   0,   2,   2,   3,\n",
       "          2]),\n",
       " array([0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "        0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.], dtype=float32),\n",
       " 0.0]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from fast.ai\n",
    "class MixedInputModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont):\n",
    "        super().__init__()\n",
    "        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embs) \n",
    "        self.n_emb, self.n_cont = n_emb, n_cont\n",
    "        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 100)\n",
    "        self.lin2 = nn.Linear(100, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.bn2 = nn.BatchNorm1d(100)\n",
    "        self.emb_drop = nn.Dropout(0.5)\n",
    "        self.drops = nn.Dropout(0.2)\n",
    "        \n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x2 = self.bn1(x_cont)\n",
    "        x = torch.cat([x, x2], 1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixedInputModel(emb_szs, 172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 248]) torch.Size([5, 172]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "x1, x2, y = next(iter(train_dl))\n",
    "print(x1.shape, x2.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3739],\n",
       "        [-0.2280],\n",
       "        [-0.2244],\n",
       "        [-0.1472],\n",
       "        [ 0.6558]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.unsqueeze(1)\n",
    "out = model(x1, x2)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (out > 0.0).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred == y).float().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7528)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.binary_cross_entropy_with_logits(out, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, train_dl=train_dl, verbose=False):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for i, (x1, x2, y) in enumerate(train_dl):\n",
    "        batch = y.shape[0]\n",
    "        y = y.unsqueeze(1)  \n",
    "        out = model(x1, x2)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y)   \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "        if verbose: print(sum_loss/total)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for i, (x1, x2, y) in enumerate(valid_dl):\n",
    "        batch = y.shape[0]\n",
    "        y = y.unsqueeze(1)\n",
    "        out = model(x1, x2)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, y)\n",
    "        sum_loss += batch*(loss.item())\n",
    "        total += batch\n",
    "        pred = (out > 0).float()\n",
    "        correct += (pred == y).float().sum().item()\n",
    "    print(\"val loss\", sum_loss/total, correct/total)\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def train_loop(model, epochs, lr=0.01, wd=0.0):\n",
    "    optim = get_optimizer(model, lr = lr, wd = wd)\n",
    "    for i in range(epochs): \n",
    "        loss = train_model(model, optim, train_dl)\n",
    "        print(\"loss \", loss)\n",
    "        val_loss(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixedInputModel(emb_szs, 172) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the higest learning rate that doesn't cycle \n",
    "#optim = get_optimizer(model, lr = 0.1, wd = 0.0)\n",
    "#train_model(model, optim, train_dl, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  0.40963991163887736\n",
      "val loss 0.28050583809148905 0.8871542043275815\n",
      "loss  0.2726559068235232\n",
      "val loss 0.24683427480892495 0.8948233360723089\n",
      "loss  0.2425833026151793\n",
      "val loss 0.24767417169880848 0.8970145165708026\n",
      "loss  0.22993842451760488\n",
      "val loss 0.24438396030519147 0.9052314434401534\n",
      "loss  0.22175926448008484\n",
      "val loss 0.2435034419642315 0.9022185702547247\n",
      "loss  0.21122783194728434\n",
      "val loss 0.24742723562658012 0.9008490824431663\n",
      "loss  0.2104358298668826\n",
      "val loss 0.2554055783592554 0.9003012873185429\n",
      "loss  0.2009587569029094\n",
      "val loss 0.2585757545814616 0.8994795946316078\n",
      "loss  0.19249877350782899\n",
      "val loss 0.26678937042585565 0.9019446726924131\n",
      "loss  0.19240531748580594\n",
      "val loss 0.25379587123407726 0.8953711311969323\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, epochs=10, lr=0.05, wd=0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate (LR) range test\n",
    "The [learning rate range test](https://arxiv.org/abs/1506.01186) is a way to estimate minimum and maximum boundary values for learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))\n",
    "\n",
    "def LR_range_finder(model, train_dl, lr_low=1e-5, lr_high=1, epochs=2):\n",
    "    losses = []\n",
    "    p = PATH/\"mode_tmp.pth\"\n",
    "    save_model(model, str(p))\n",
    "    iterations = epochs * len(train_dl)\n",
    "    delta = (lr_high - lr_low)/iterations\n",
    "    lrs = [lr_low + i*delta for i in range(iterations)]\n",
    "    model.train()\n",
    "    ind = 0\n",
    "    for i in range(epochs):\n",
    "        for j, (x1, x2, y) in enumerate(train_dl):\n",
    "            # changing learning rate at each iteration\n",
    "            optim = get_optimizer(model, lr=lrs[ind])\n",
    "            batch = y.shape[0]\n",
    "            y = y.unsqueeze(1)  \n",
    "            out = model(x1, x2)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y)   \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            losses.append(loss.item())\n",
    "            ind +=1\n",
    "            \n",
    "    load_model(model, str(p))\n",
    "    return lrs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)\n",
    "model = MixedInputModel(emb_szs, 172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_low, lr_high and batch_size are important so that the plot gives\n",
    "# useful information\n",
    "lrs, losses = LR_range_finder(model, train_dl, lr_low=1e-5, lr_high=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lrs, losses)\n",
    "#plt.plot(lrs[:30], losses[:30])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick the lower boundary as the value of the learning rate when the loss starts to decrease. Pick the upper learning rate when the loss slows, becomes ragged or increases. From this graph I would try $base\\_lr=1e-5$ and $max\\_lr=0.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One cycle learning rate policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triangular_lr2(lr_low, lr_high, stepesize):\n",
    "    iterations = 2*stepesize\n",
    "    iter1 = int(0.35*iterations)\n",
    "    iter2 = int(0.85*iter1)\n",
    "    iter3 = iterations - iter1 - iter2\n",
    "    delta1 = (lr_high - lr_low)/iter1\n",
    "    delta2 = (lr_high - lr_low)/(iter1 -1)\n",
    "    lrs1 = [lr_low + i*delta1 for i in range(iter1)]\n",
    "    lrs2 = [lr_high - i*(delta1) for i in range(0, iter2)]\n",
    "    delta2 = (lrs2[-1] - lr_low)/(iter3)\n",
    "    lrs3 = [lrs2[-1] - i*(delta2) for i in range(1, iter3+1)]\n",
    "    return lrs1+lrs2+lrs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lrs = get_triangular_lr2(1e-5, 0.1, 700)\n",
    "plt.plot(lrs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_triangular_policy(model, train_dl, valid_dl, lr_low=1e-5, lr_high=0.01, epochs=4):\n",
    "    idx = 0\n",
    "    stepesize = (epochs//2)*len(train_dl)\n",
    "    lrs = get_triangular_lr2(lr_low, lr_high, stepesize)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for i, (x1, x2, y) in enumerate(train_dl):\n",
    "            optim = get_optimizer(model, lr = lrs[idx], wd = 0.00001)\n",
    "            batch = y.shape[0]\n",
    "            y = y.unsqueeze(1)  \n",
    "            out = model(x1, x2)\n",
    "            loss = F.binary_cross_entropy_with_logits(out, y) \n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            idx += 1\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "        print(\"train loss\", sum_loss/total)\n",
    "        val_loss(model, valid_dl)\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MixedInputModel(emb_szs, 172)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.24587600113136807\n",
      "val loss 0.24231754755588533 0.9046836483155299\n",
      "train loss 0.27715584174537294\n",
      "val loss 0.2697011732264957 0.8912626677622569\n",
      "train loss 0.3259971583013631\n",
      "val loss 0.325057807229245 0.8803067652697891\n",
      "train loss 0.30987580536457326\n",
      "val loss 0.26951411781132106 0.8945494385099972\n",
      "train loss 0.2618389627241951\n",
      "val loss 0.2285546188287884 0.9063270336894002\n",
      "train loss 0.2426936120790705\n",
      "val loss 0.22571344336918758 0.9098877019994522\n",
      "train loss 0.23826666781997655\n",
      "val loss 0.22648271440773982 0.9060531361270885\n",
      "train loss 0.2324035341847077\n",
      "val loss 0.22461075986110815 0.9101615995617639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2324035341847077"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triangular_policy(model, train_dl, valid_dl, lr_low=1e-6, lr_high=0.08, epochs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Get a better validation score by hyper-parameter tunning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
